{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc12cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d296aa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mahes\\\\OneDrive\\\\Desktop\\\\mdf\\\\spam cv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmahes\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmdf\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mspam cv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mahes\\\\OneDrive\\\\Desktop\\\\mdf\\\\spam cv.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\mahes\\OneDrive\\Desktop\\mdf\\spam cv.csv', encoding='latin1')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class=pd.value_counts(data[\"v1\"], sort= True)\n",
    "count_Class.plot(kind= 'bar', color= [\"blue\", \"orange\"])\n",
    "plt.title('Bar chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_Class.plot(kind = 'pie',  autopct='%1.0f%%')\n",
    "plt.title('Pie chart')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e633ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Analytics\n",
    "'''We want to find the frequencies of words in the spam and non-spam messages. The words of the messages will be model features.\n",
    "\n",
    "We use the function Counter.'''\n",
    "count1 = Counter(\" \".join(data[data['v1']=='ham'][\"v2\"]).split()).most_common(20)\n",
    "df1 = pd.DataFrame.from_dict(count1)\n",
    "df1 = df1.rename(columns={0: \"words in non-spam\", 1 : \"count\"})\n",
    "count2 = Counter(\" \".join(data[data['v1']=='spam'][\"v2\"]).split()).most_common(20)\n",
    "df2 = pd.DataFrame.from_dict(count2)\n",
    "df2 = df2.rename(columns={0: \"words in spam\", 1 : \"count_\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot.bar(legend = False)\n",
    "y_pos = np.arange(len(df1[\"words in non-spam\"]))\n",
    "plt.xticks(y_pos, df1[\"words in non-spam\"])\n",
    "plt.title('More frequent words in non-spam messages')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.plot.bar(legend = False, color = 'orange')\n",
    "y_pos = np.arange(len(df2[\"words in spam\"]))\n",
    "plt.xticks(y_pos, df2[\"words in spam\"])\n",
    "plt.title('More frequent words in spam messages')\n",
    "plt.xlabel('words')\n",
    "plt.ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5372e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We can see that the majority of frequent words in both classes are stop words such as 'to', 'a', 'or' and so on.\n",
    "\n",
    "With stop words we refer to the most common words in a lenguage, there is no simgle, universal list of stop words.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = feature_extraction.text.CountVectorizer(stop_words = 'english')\n",
    "X = f.fit_transform(data[\"v2\"])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146abd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We have created more than 8400 new features. The new feature  j  in the row  i  is equal to 1 if the word  wj appears in the text example  i . It is zero if not.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c458c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictive Analysis\n",
    "'''My goal is to predict if a new sms is spam or non-spam. I assume that is much worse misclassify non-spam than misclassify an spam. (I don't want to have false positives)\n",
    "\n",
    "The reason is because I normally don't check the spam messages.\n",
    "\n",
    "The two possible situations are:\n",
    "\n",
    "New spam sms in my inbox. (False negative).\n",
    "OUTCOME: I delete it.\n",
    "\n",
    "New non-spam sms in my spam folder (False positive).\n",
    "OUTCOME: I probably don't read it.\n",
    "\n",
    "I prefer the first option!!!\n",
    "\n",
    "First we transform the variable spam/non-spam into binary variable, then we split our data set in training set and test set.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"v1\"]=data[\"v1\"].map({'spam':1,'ham':0})\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, data['v1'], test_size=0.33, random_state=42)\n",
    "print([np.shape(X_train), np.shape(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial naive bayes classifier\n",
    "'''We train different bayes models changing the regularization parameter  Î± .\n",
    "\n",
    "We evaluate the accuracy, recall and precision of the model with the test set.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2702dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_alpha = np.arange(1/100000, 20, 0.11)\n",
    "score_train = np.zeros(len(list_alpha))\n",
    "score_test = np.zeros(len(list_alpha))\n",
    "recall_test = np.zeros(len(list_alpha))\n",
    "precision_test= np.zeros(len(list_alpha))\n",
    "count = 0\n",
    "for alpha in list_alpha:\n",
    "    bayes = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    bayes.fit(X_train, y_train)\n",
    "    score_train[count] = bayes.score(X_train, y_train)\n",
    "    score_test[count]= bayes.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, bayes.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, bayes.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the first 10 learning models and their metrics!\n",
    "matrix = np.matrix(np.c_[list_alpha, score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['alpha', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef71b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I select the model with the most test precision\n",
    "best_index = models['Test Precision'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f370ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''My best model does not produce any false positive, which is our goal.\n",
    "\n",
    "Let's see if there is more than one model with 100% precision !'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[models['Test Precision']==1].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Between these models with the highest possible precision, we are going to select which has more test accuracy.\n",
    "best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\n",
    "bayes = naive_bayes.MultinomialNB(alpha=list_alpha[best_index])\n",
    "bayes.fit(X_train, y_train)\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix with naive bayes classifier\n",
    "m_confusion_test = metrics.confusion_matrix(y_test, bayes.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377babd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### We misclassify 56 spam messages as non-spam emails whereas we don't misclassify any non-spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Support Vector Machine\n",
    "We are going to apply the same reasoning applying the support vector machine model with the gaussian kernel.\n",
    "\n",
    "We train different models changing the regularization parameter C.\n",
    "\n",
    "We evaluate the accuracy, recall and precision of the model with the test set.'''\n",
    "list_C = np.arange(500, 2000, 100) #100000\n",
    "score_train = np.zeros(len(list_C))\n",
    "score_test = np.zeros(len(list_C))\n",
    "recall_test = np.zeros(len(list_C))\n",
    "precision_test= np.zeros(len(list_C))\n",
    "count = 0\n",
    "for C in list_C:\n",
    "    svc = svm.SVC(C=C)\n",
    "    svc.fit(X_train, y_train)\n",
    "    score_train[count] = svc.score(X_train, y_train)\n",
    "    score_test[count]= svc.score(X_test, y_test)\n",
    "    recall_test[count] = metrics.recall_score(y_test, svc.predict(X_test))\n",
    "    precision_test[count] = metrics.precision_score(y_test, svc.predict(X_test))\n",
    "    count = count + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see the first 10 learning models and their metrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf529e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.matrix(np.c_[list_C, score_train, score_test, recall_test, precision_test])\n",
    "models = pd.DataFrame(data = matrix, columns = \n",
    "             ['C', 'Train Accuracy', 'Test Accuracy', 'Test Recall', 'Test Precision'])\n",
    "models.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = models['Test Precision'].idxmax()\n",
    "models.iloc[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''My best model does not produce any false positive, which is our goal.\n",
    "\n",
    "Let's see if there is more than one model with 100% precision !'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[models['Test Precision']==1].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ec7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Between these models with the highest possible precision, we are going to selct which has more test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_models = models[models['Test Precision'] == 1]\n",
    "#best_index = models[models['Test Precision']==1]['Test Accuracy'].idxmax()\n",
    "\n",
    "if not filtered_models.empty:\n",
    "    #best_index = filtered_models['Test Accuracy'].idxmax()\n",
    "    svc = svm.SVC(C=list_C[best_index])\n",
    "    svc.fit(X_train, y_train)\n",
    "    models.iloc[best_index, :]\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a48345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix with support vector machine classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777755ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_confusion_test = metrics.confusion_matrix(y_test, svc.predict(X_test))\n",
    "pd.DataFrame(data = m_confusion_test, columns = ['Predicted 0', 'Predicted 1'],\n",
    "            index = ['Actual 0', 'Actual 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We misclassify 37 spam as non-spam messages whereas we don't misclassify any non-spam message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7c6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Conclusion\n",
    "The best model I have found is support vector machine with 98.3% accuracy.\n",
    "\n",
    "It classifies every non-spam message correctly (Model precision)\n",
    "\n",
    "It classifies the 87.7% of spam messages correctly (Model recall)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
